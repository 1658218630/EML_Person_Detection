{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5957f000-626f-461b-8349-42cf13c69225",
   "metadata": {},
   "source": [
    "# Load Vision Model\n",
    "\n",
    "First we load in the data and our model into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc8843-8317-42cb-8df8-f73ce05c8c26",
   "metadata": {},
   "source": [
    "**Important:** For this notebook to function it needs to be execuetd with `export LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1:/$LD_PRELOAD` else you will get a error. \n",
    "I included this in jupyter by adding a docker environment variable: `-e LD_PRELOAD=/usr/lib/aarch64-linux-gnu/libgomp.so.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d608437-5301-4afc-b0f6-38940f772c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadf5a56-5b7e-471d-a20f-8877c8da133c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyYoloV2(\n",
       "  (pad): ReflectionPad2d((0, 1, 0, 1))\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinyyolov2 import TinyYoloV2\n",
    "from utils.yolo import nms, filter_boxes\n",
    "from utils.viz import display_result\n",
    "\n",
    "# make an instance with 20 classes as output\n",
    "net = TinyYoloV2(num_classes=20)\n",
    "\n",
    "# load pretrained weights\n",
    "sd = torch.load(\"voc_pretrained.pt\")\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "#put network in evaluation mode\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9c991-2879-4cfc-9cba-fd2b2c872656",
   "metadata": {},
   "source": [
    "# Define Camera Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2717d23b-f432-4990-9830-b9c981ddcbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.camera import CameraDisplay\n",
    "import time\n",
    "import cv2\n",
    "now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512b8f8c-7a96-459b-8851-4a94041bf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To control log spamming\n",
    "frame_counter = 0  # Counts frames\n",
    "debug_interval = 10  # Log every 30 frames\n",
    "\n",
    "# How sensitive the model is \n",
    "confidence_val = 0.0001 # default: 0.1\n",
    "overlap_val = 0.05 # default: 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45469fe-b164-4633-b3d4-78d21612bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(image):\n",
    "    global frame_counter\n",
    "    img_shape = 320\n",
    "\n",
    "    # Ensure the input tensor is correct\n",
    "    if image.shape != (1, 3, 320, 320):\n",
    "        raise ValueError(f\"Invalid input shape: {image.shape}, expected (1, 3, 320, 320)\")\n",
    "\n",
    "    # Pass through the network\n",
    "    with torch.no_grad():\n",
    "        output = net(image)\n",
    "\n",
    "    # Process YOLO output\n",
    "    output = filter_boxes(output, confidence_val)\n",
    "\n",
    "    output = nms(output, overlap_val)\n",
    "\n",
    "    # Convert the tensor back to a NumPy array for OpenCV\n",
    "    image_np = image.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    image_np = (image_np * 255).astype(np.uint8)  # Scale back to 0-255 and convert to uint\n",
    "\n",
    "    if output:\n",
    "        if frame_counter % debug_interval == 0:\n",
    "            print(f\"Frame {frame_counter}: output not empty.\")\n",
    "        bboxes = torch.stack(output, dim=0)\n",
    "\n",
    "        if frame_counter % debug_interval == 0:\n",
    "            print(f\"Frame {frame_counter}: Number of bboxes: {bboxes.shape[1]}\")\n",
    "        \n",
    "        for i in range(bboxes.shape[1]):\n",
    "            # Extract box information\n",
    "            cx = bboxes[0, i, 0].item()\n",
    "            cy = bboxes[0, i, 1].item()\n",
    "            w = bboxes[0, i, 2].item()\n",
    "            h = bboxes[0, i, 3].item()\n",
    "            conf = bboxes[0, i, 4].item()\n",
    "            class_id = int(bboxes[0, i, 5].item())\n",
    "            class_name = num_to_class(class_id)\n",
    "\n",
    "            if frame_counter % debug_interval == 0:\n",
    "                print(f\"Detection {i}: Center=({cx:.2f}, {cy:.2f}), Size=({w:.2f}, {h:.2f}), \"\n",
    "                      f\"conf={conf:.2f}, Class={class_name} ({class_id})\")\n",
    "\n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            x_min = int((cx - w / 2) * img_shape)\n",
    "            y_min = int((cy - h / 2) * img_shape)\n",
    "            x_max = int((cx + w / 2) * img_shape)\n",
    "            y_max = int((cy + h / 2) * img_shape)\n",
    "\n",
    "            # Verify if coordinates are within bounds\n",
    "            if x_min < 0 or y_min < 0 or x_max > img_shape or y_max > img_shape:\n",
    "                print(f\"Detection {i}: Bounding box out of bounds! ({x_min}, {y_min}, {x_max}, {y_max})\")\n",
    "\n",
    "            # Draw rectangle on the image\n",
    "            cv2.rectangle(\n",
    "                image_np,\n",
    "                (x_min, y_min),\n",
    "                (x_max, y_max),\n",
    "                (0, 0, 255),  # Red\n",
    "                2\n",
    "            )\n",
    "\n",
    "            # Add label text\n",
    "            label = f\"{class_name} {conf:.2f}\"\n",
    "            cv2.putText(\n",
    "                image_np,\n",
    "                label,\n",
    "                (x_min, y_min - 10),  # Slightly above the rectangle\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,  # Font scale\n",
    "                (0, 0, 255),  # Red\n",
    "                1  # Thickness\n",
    "            )\n",
    "    else:\n",
    "        if frame_counter % debug_interval == 0:\n",
    "            print(f\"Frame {frame_counter}: No detections.\")\n",
    "\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2be5c5f-2862-4e1c-b4fa-0de8c6849d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(image):\n",
    "    global now, frame_counter\n",
    "\n",
    "    frame_counter += 1\n",
    "    if image is None:\n",
    "        raise ValueError(\"Received empty frame from the camera.\")\n",
    "\n",
    "    # Resize and preprocess the image\n",
    "    img_resized = cv2.resize(image, (320, 320))\n",
    "    img_tensor = torch.tensor(img_resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "\n",
    "    # Predict and visualize\n",
    "    img_with_predictions = get_predictions(img_tensor)\n",
    "\n",
    "    # Add FPS to the image\n",
    "    fps = f\"{int(1 / (time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    cv2.putText(img_with_predictions, f\"fps={fps}\", (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return img_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235e8da7-9935-4843-bac0-aa41a66e2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing camera...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Argus) Error Timeout:  (propagating from src/rpc/socket/client/SocketClientDispatch.cpp, function openSocketConnection(), line 219)\n",
      "(Argus) Error Timeout: Cannot create camera provider (in src/rpc/socket/client/SocketClientDispatch.cpp, function createCameraProvider(), line 106)\n",
      "Error generated. /dvs/git/dirty/git-master_linux/multimedia/nvgstreamer/gst-nvarguscamera/gstnvarguscamerasrc.cpp, execute:735 Failed to create CameraProvider\n",
      "[ WARN:0@60.664] global cap_gstreamer.cpp:1777 open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not initialize camera.  Please see error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/embedded-ml-lab-students-ws2425/exercises/4-challenge/utils/camera.py:38\u001b[0m, in \u001b[0;36mCamera.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not read image from camera.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not read image from camera.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the camera with the callback\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cam \u001b[38;5;241m=\u001b[39m \u001b[43mCameraDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embedded-ml-lab-students-ws2425/exercises/4-challenge/utils/camera.py:86\u001b[0m, in \u001b[0;36mCameraDisplay.__init__\u001b[0;34m(self, img_to_display_img_callback, lazy_camera_init)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_camera_init \u001b[38;5;241m=\u001b[39m lazy_camera_init\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_camera_init:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embedded-ml-lab-students-ws2425/exercises/4-challenge/utils/camera.py:98\u001b[0m, in \u001b[0;36mCameraDisplay.initialize_camera\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_camera\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitializing camera...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera \u001b[38;5;241m=\u001b[39m \u001b[43mCamera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m360\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_fps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mobserve(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_camera_callback, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/embedded-ml-lab-students-ws2425/exercises/4-challenge/utils/camera.py:40\u001b[0m, in \u001b[0;36mCamera.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not read image from camera.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not initialize camera.  Please see error trace.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mrelease)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not initialize camera.  Please see error trace."
     ]
    }
   ],
   "source": [
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb687c4-8ee6-4ec8-b496-547954b0b3bc",
   "metadata": {},
   "source": [
    "# Camera Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c204d-bf7e-4e28-a4a9-787d6f738996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The camera stream can be started with cam.start()\n",
    "# The callback gets asynchronously called (can be stopped with cam.stop())\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a0630-2ca5-4055-8d7d-1a12259afc48",
   "metadata": {},
   "source": [
    "Execute below, to stop camera loop.\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc7b5d0a-a74b-4537-a76e-22fa16be1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "# The camera should always be stopped and released for a new camera is instantiated (calling CameraDisplay(callback) again)\n",
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659cc34-3bf8-4b3a-9e60-675eb95c68b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
